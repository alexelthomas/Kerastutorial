{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crash Course in Neural Networks with Keras\n",
    "This is a brief introduction to using Keras, which will also teach you a bit about neural networks along the way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import keras, glob\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Neural Network = Model\n",
    "In broad terms machine learning is teaching a machine the relation between some input, $x$ and some output $y$, so \n",
    "\n",
    "$y = f(x, a) $\n",
    "\n",
    "where $a$ is a set of parameters that define the function $f$.\n",
    "\n",
    "A neural network can therefore be thought of as a model $f$ that has a set of parameters, $a$, that you try to optimize to best predict the relation between, a set of training images and their labels. \n",
    "\n",
    "Neural networks can also be used for regression problems, and very simplified analogy would be a very complicated, high-order polynomial. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequential models\n",
    "Most neural networks, or models, you can construct with Keras fall under the sequential model type. This is the 'typical' network seen in most illustrations, and consists of a sequence of layers that each take inputs from neurons in the preceding layer, perform some operation depending on the layer type, and then feed it forward into the next layer in the sequence.\n",
    "\n",
    "In 'classical' code, this would look something like:\n",
    "```python\n",
    "y = input(x)\n",
    "y = layer1_func(y)\n",
    "y = layer2_func(y)\n",
    "y = output(y)\n",
    "```\n",
    "\n",
    "Keras gives access to many types of layers, corresponding to different arithmetic functions and array manipulations. Keras allows you to mix and match these layers in your sequence, and will automatically sort out the connections between them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising a sequential model\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Classification\n",
    "This sets up a simple image classifier, to classify images of cats and dogs.\n",
    "\n",
    "### Setting up data\n",
    "#### Training data\n",
    "To set up a training set, all you need to do it create a directory, where sub-directories correspond to each class. \n",
    "\n",
    "Example:\n",
    "\n",
    "/home/training_set/cats\n",
    "\n",
    "/home/training_set/dogs\n",
    "\n",
    "Keras then only needs to be pointed at /home/training_set and it will figure out the classes, in this case cats and dogs.\n",
    "\n",
    "#### Validation data\n",
    "The training data that the network never sees.\n",
    "\n",
    "#### Testing data\n",
    "The data neither you or the network have seen. Performance on this is what you put in the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory where you have placed your training data\n",
    "training_dir = '/home/nielsemb/work/Teaching/Keras_Tutorial/training_set' # EDIT THIS\n",
    "validation_dir = '/home/nielsemb/work/Teaching/Keras_Tutorial/validation_set' # EDIT THIS\n",
    "testing_dir = '/home/nielsemb/work/Teaching/Keras_Tutorial/test_set' # EDIT THIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Generators\n",
    "Data generators are functions used for ingesting data and feeding it into your network, with some degree of manupulations along the way. They are typically used to feed in small batches of the training data, so as to conserve memory in case the training set is very large.\n",
    "\n",
    "For image classification Keras has a built in class ImageDataGenerator that does this, and also preprocesses the images, and can perform data augmentation. \n",
    "\n",
    "#### Preprocessing\n",
    "Image data comes in a variety of different shapes, sizes and formats. Your network will only function or at least function well, on images that are preprocessed in a similar fashion to what it's been trained on. It's therefore useful to establish a format specific for your network. These include, rescaling the pixel values to be between 0 and 255 (png standard), binning or interpolating the image to a specific shape. \n",
    "\n",
    "#### Data Augmentation\n",
    "In general purpose classification it is sometimes useful to alter the training data in some way. This makes the network able to handle a greater variation in the unseen data. It can also be used to artificially increase the number of training examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2536 images belonging to 2 classes.\n",
      "Found 799 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Image preprocessing\n",
    "image_dim = (64, 64) # Image dimensions, important for network arch.\n",
    "rescale = 1./255 # Rescale pixel values to minimum 0, maximum 255\n",
    "\n",
    "# Data Augmentation\n",
    "shear_range = 0.2 # Randomly shearing the image alonge either axis\n",
    "zoom_range = 0.2 # Randomly zoom in on parts of the image \n",
    "horizontal_flip = True # Randomly flip images horizontaly\n",
    "\n",
    "# Training-time parameters\n",
    "batchsize = 32 # no. of images generator yields each call\n",
    "shuffle = True # randomize the training set\n",
    "class_mode = 'binary' # specific to network type, classifiers can be 'binary' or 'categorical'\n",
    "\n",
    "# Initialize the ImageDataGenerator class\n",
    "train_datagen = ImageDataGenerator(rescale = rescale, \n",
    "                                   shear_range = shear_range, \n",
    "                                   zoom_range = zoom_range,\n",
    "                                   horizontal_flip = horizontal_flip) \n",
    "\n",
    "# Setup the ImageDataGenerator instance to ingest images from training_dir\n",
    "training_set = train_datagen.flow_from_directory(training_dir,\n",
    "                                                 target_size = image_dim, \n",
    "                                                 batch_size = batchsize, \n",
    "                                                 shuffle = shuffle,\n",
    "                                                 class_mode = class_mode)\n",
    "\n",
    "\n",
    "# Initialize the ImageDataGenerator class\n",
    "validation_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "# Setup the ImageDataGenerator instance to ingest images from training_dir\n",
    "validation_set = validation_datagen.flow_from_directory(validation_dir,\n",
    "                                                        target_size = image_dim,\n",
    "                                                        batch_size = batchsize,\n",
    "                                                        class_mode = class_mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/nielsemb/anaconda3/envs/kerasenv/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/nielsemb/anaconda3/envs/kerasenv/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "conv_kernel = (3,3)\n",
    "model.add(Conv2D(32, conv_kernel, input_shape = (image_dim[0], image_dim[1], 3), activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "model.add(Dropout(rate = 0.1))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units = 1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/nielsemb/anaconda3/envs/kerasenv/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/25\n",
      "79/79 [==============================] - 6s 74ms/step - loss: 0.6845 - acc: 0.5672 - val_loss: 0.7402 - val_acc: 0.5026\n",
      "Epoch 2/25\n",
      "79/79 [==============================] - 5s 66ms/step - loss: 0.6288 - acc: 0.6448 - val_loss: 0.6604 - val_acc: 0.6076\n",
      "Epoch 3/25\n",
      "79/79 [==============================] - 5s 66ms/step - loss: 0.6082 - acc: 0.6642 - val_loss: 0.6231 - val_acc: 0.6610\n",
      "Epoch 4/25\n",
      "79/79 [==============================] - 5s 66ms/step - loss: 0.5790 - acc: 0.6867 - val_loss: 0.6604 - val_acc: 0.6310\n",
      "Epoch 5/25\n",
      "79/79 [==============================] - 5s 66ms/step - loss: 0.5727 - acc: 0.7029 - val_loss: 0.7624 - val_acc: 0.5724\n",
      "Epoch 6/25\n",
      "79/79 [==============================] - 5s 66ms/step - loss: 0.5621 - acc: 0.7065 - val_loss: 0.6003 - val_acc: 0.6832\n",
      "Epoch 7/25\n",
      "79/79 [==============================] - 5s 66ms/step - loss: 0.5485 - acc: 0.7156 - val_loss: 0.5979 - val_acc: 0.6845\n",
      "Epoch 8/25\n",
      "79/79 [==============================] - 5s 66ms/step - loss: 0.5547 - acc: 0.7144 - val_loss: 0.6250 - val_acc: 0.6584\n",
      "Epoch 9/25\n",
      "79/79 [==============================] - 5s 67ms/step - loss: 0.5278 - acc: 0.7362 - val_loss: 0.6269 - val_acc: 0.6884\n",
      "Epoch 10/25\n",
      "79/79 [==============================] - 5s 66ms/step - loss: 0.5226 - acc: 0.7310 - val_loss: 0.5789 - val_acc: 0.7093\n",
      "Epoch 11/25\n",
      "79/79 [==============================] - 5s 67ms/step - loss: 0.5200 - acc: 0.7397 - val_loss: 0.6946 - val_acc: 0.6389\n",
      "Epoch 12/25\n",
      "79/79 [==============================] - 5s 66ms/step - loss: 0.5044 - acc: 0.7579 - val_loss: 0.5797 - val_acc: 0.6988\n",
      "Epoch 13/25\n",
      "79/79 [==============================] - 5s 66ms/step - loss: 0.4994 - acc: 0.7627 - val_loss: 0.6319 - val_acc: 0.6780\n",
      "Epoch 14/25\n",
      "79/79 [==============================] - 5s 66ms/step - loss: 0.4998 - acc: 0.7524 - val_loss: 0.6394 - val_acc: 0.7040\n",
      "Epoch 15/25\n",
      "79/79 [==============================] - 5s 66ms/step - loss: 0.4953 - acc: 0.7654 - val_loss: 0.6641 - val_acc: 0.6688\n",
      "Epoch 16/25\n",
      "79/79 [==============================] - 5s 66ms/step - loss: 0.4718 - acc: 0.7761 - val_loss: 0.5988 - val_acc: 0.6780\n",
      "Epoch 17/25\n",
      "79/79 [==============================] - 5s 66ms/step - loss: 0.4768 - acc: 0.7729 - val_loss: 0.6302 - val_acc: 0.6936\n",
      "Epoch 18/25\n",
      "79/79 [==============================] - 5s 67ms/step - loss: 0.4926 - acc: 0.7571 - val_loss: 0.8075 - val_acc: 0.6154\n",
      "Epoch 19/25\n",
      "79/79 [==============================] - 5s 66ms/step - loss: 0.4557 - acc: 0.7872 - val_loss: 0.5683 - val_acc: 0.7288\n",
      "Epoch 20/25\n",
      "79/79 [==============================] - 5s 67ms/step - loss: 0.4691 - acc: 0.7706 - val_loss: 0.7007 - val_acc: 0.6754\n",
      "Epoch 21/25\n",
      "79/79 [==============================] - 5s 66ms/step - loss: 0.4499 - acc: 0.7931 - val_loss: 0.6976 - val_acc: 0.6806\n",
      "Epoch 22/25\n",
      "79/79 [==============================] - 5s 66ms/step - loss: 0.4609 - acc: 0.7781 - val_loss: 0.5961 - val_acc: 0.7301\n",
      "Epoch 23/25\n",
      "79/79 [==============================] - 5s 66ms/step - loss: 0.4576 - acc: 0.7840 - val_loss: 0.6032 - val_acc: 0.7132\n",
      "Epoch 24/25\n",
      "79/79 [==============================] - 5s 66ms/step - loss: 0.4603 - acc: 0.7816 - val_loss: 0.7363 - val_acc: 0.6532\n",
      "Epoch 25/25\n",
      "79/79 [==============================] - 5s 66ms/step - loss: 0.4561 - acc: 0.7876 - val_loss: 0.7299 - val_acc: 0.6728\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f04d8e36a90>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(training_set, \n",
    "                    steps_per_epoch = int(training_set.samples/batchsize), \n",
    "                    epochs = 25, \n",
    "                    validation_data = validation_set,\n",
    "                    validation_steps = int(validation_set.samples/batchsize))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/nielsemb/work/Teaching/Keras_Tutorial/test_set/dogs/dog.4027.jpg\n",
      "dog\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import image\n",
    "\n",
    "# Part 3 - Making new predictions\n",
    "random_image_path = np.random.choice(glob.glob(testing_dir+'/*/*'))\n",
    "\n",
    "test_image = image.load_img(random_image_path, target_size = image_dim)\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "result = model.predict(test_image)\n",
    "training_set.class_indices\n",
    "if result[0][0] == 1:\n",
    "    prediction = 'dog'\n",
    "else:\n",
    "    prediction = 'cat'\n",
    "\n",
    "print(random_image_path)    \n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Transfer Learning"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
